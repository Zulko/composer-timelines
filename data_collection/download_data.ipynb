{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8ba556-dcb5-4285-8d57-c41aef60447d",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20375bc0-8467-42b6-85bb-e37b2c81ac04",
   "metadata": {},
   "source": [
    "## Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "246fffa4-d6b2-4740-b160-cc0a1b07d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "from gpt_function_decorator import gpt_function\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "from fastprogress import progress_bar\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def process_files(function, source_folder, target_folder=None, replace_existing=False, num_processes=1):\n",
    "    source_folder = Path(source_folder)\n",
    "    source_files = list(source_folder.glob(\"*\"))\n",
    "    if not replace_existing:\n",
    "        target_folder = Path(target_folder)\n",
    "        target_folder.mkdir(parents=True, exist_ok=True)\n",
    "        already_processed = {f.stem for f in target_folder.glob(\"*\")}\n",
    "        source_files = [f for f in source_files if f.stem not in already_processed]\n",
    "    if (len(source_files) > 1) and (num_processes > 1):\n",
    "        with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "             list(progress_bar(pool.imap(function, source_files), total=len(source_files)))\n",
    "    else:\n",
    "        for file in progress_bar(source_files):\n",
    "            function(file)\n",
    "\n",
    "@lru_cache\n",
    "def download_page(url, target_file=None, sleep_after=0):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        html = response.text\n",
    "        time.sleep(sleep_after)\n",
    "        if target_file is not None:\n",
    "            Path(target_file).write_text(html)\n",
    "        return html\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "\n",
    "def chunk_list(mylist, chunk_size, overlap=0):\n",
    "    return [mylist[i:i + chunk_size + overlap] for i in range(0, len(mylist), chunk_size)]\n",
    "        \n",
    "def save_to_json(data, filepath):\n",
    "    json.dump(data, open(filepath, \"w\"), indent=2)\n",
    "\n",
    "def load_from_json(filepath):\n",
    "    return json.load(open(filepath, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c707f-9737-4f4a-ba58-81edc4d251e7",
   "metadata": {},
   "source": [
    "## Generate the composer list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627bb5a0-e731-4a1d-b9a2-02977105ba78",
   "metadata": {},
   "source": [
    "### Ask for a list of composers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83935d0f-0308-4222-8dd7-03810e7b0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@gpt_function(gpt_model='gpt-4o', retries=2)\n",
    "def list_famous_composers(n_composers) -> list:\n",
    "    \"\"\"Return a list of the most famous classical composers\n",
    "    who lived between 1600 before 1976\"\"\"\n",
    "\n",
    "target_file = Path(\"./data/composer_list.json\")\n",
    "if not target_file.is_file():\n",
    "    composers = [\n",
    "        composer\n",
    "        for i in progress_bar(range(10))\n",
    "        for composer in list_famous_composers(n_composers=100)\n",
    "    ]\n",
    "    unique_composers = set(composers)\n",
    "    composers_list = [c for c in composer_counts if composer_counts[c] > 1]\n",
    "    save_to_json(composers_list, target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741ebfb-c01d-4aa8-a34d-516a51c826c0",
   "metadata": {},
   "source": [
    "### Make one file per composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55232f89-a87c-4497-b29b-9662e232d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer_list = load_from_json(\"./data/composer_list.json\")\n",
    "path = Path(\"data/composer_names\")\n",
    "path.mkdir(exist_ok=True)\n",
    "for composer in composer_list:\n",
    "    save_to_json({\"name\": composer}, path / f\"{composer}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044f203-af0c-4ba7-b4be-63eb52e0aae6",
   "metadata": {},
   "source": [
    "### Compute basic metadata on each composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ef26a9e-dea9-4eb8-81bd-449f2937cb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='151' class='' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [151/151 01:09&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@gpt_function(gpt_model='gpt-4o', retries=2)\n",
    "def composer_metadata(composer) -> dict:\n",
    "    \"\"\"Return the following metadata for the given composer:\n",
    "    {\n",
    "        full_name: str,\n",
    "        first_names: str,\n",
    "        last_name: str,\n",
    "        birth_year: int,\n",
    "        death_year: int\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "target_folder = Path(\"./data/composer_basic_metadata/\")\n",
    "\n",
    "def compute_basic_metadata(source_file):\n",
    "    file_data = load_from_json(source_file)\n",
    "    output = composer_metadata(composer=file_data[\"name\"])\n",
    "    save_to_json(output, target_folder / source_file.name)\n",
    "\n",
    "\n",
    "process_files(\n",
    "    compute_basic_metadata,\n",
    "    source_folder=\"./data/composer_names\",\n",
    "    target_folder=target_folder,\n",
    "    num_processes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784213d-4a87-4553-b5ae-d3d0ad797564",
   "metadata": {},
   "source": [
    "## Summarize composer wiki pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1f5cd-877b-43dd-989c-db98d8bbeed7",
   "metadata": {},
   "source": [
    "### Find the composer pages urls via a wiki search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e7e8b8b-35f6-4494-93e1-3cc3984ce625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='151' class='' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [151/151 01:12&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_wikipedia_url_from_search(term, sleep_after=1):\n",
    "    search_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": term,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(search_url, params=params)\n",
    "    data = response.json()\n",
    "    time.sleep(sleep_after)\n",
    "    \n",
    "    if data['query']['search']:\n",
    "        title = data['query']['search'][0]['title']\n",
    "        page_url = f\"https://en.wikipedia.org/wiki/{title.replace(' ', '_')}\"\n",
    "        return page_url\n",
    "    else:\n",
    "        print (f\"No page found for {term}\")\n",
    "        return None\n",
    "    \n",
    "target_folder = Path(\"data/composer_wikipedia_urls/\")\n",
    "\n",
    "def get_composer_wikipedia_url(source_file):\n",
    "    file_data = load_from_json(source_file)\n",
    "    url = get_wikipedia_url_from_search(term=file_data[\"name\"])\n",
    "    save_to_json({\"url\": url}, target_folder / source_file.name)\n",
    "\n",
    "\n",
    "process_files(\n",
    "    get_composer_wikipedia_url,\n",
    "    source_folder=\"./data/composer_names\",\n",
    "    target_folder=target_folder,\n",
    "    num_processes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877cbbce-0b16-474e-b05b-1ddaee8db11e",
   "metadata": {},
   "source": [
    "### Download the composer wiki pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "578994b2-303e-41d3-8be3-53a5815eabdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='151' class='' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [151/151 01:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_folder = Path(\"data/composer_wikipedia_pages/\")\n",
    "\n",
    "def download_composer_wikipedia_page(source_file):\n",
    "    url = load_from_json(source_file)[\"url\"]\n",
    "    target_file = target_folder / source_file.with_suffix(\".html\").name\n",
    "    download_page(url, target_file=target_file, sleep_after=1)\n",
    "\n",
    "process_files(\n",
    "    download_composer_wikipedia_page,\n",
    "    source_folder=\"./data/composer_wikipedia_urls/\",\n",
    "    target_folder=target_folder,\n",
    "    num_processes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb0de6-c453-47a8-902b-28292c3a105f",
   "metadata": {},
   "source": [
    "### Extract sections from composer webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cf608730-b341-4ab3-bc9c-0adce1063d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections_from_wikipedia_page(html_content, section_blacklist=(), section_whitelist=()):\n",
    "    \"\"\"wikipedia pages have the following slightly complex schema:\n",
    "\n",
    "    <div><h2>Section 1 title</h2></div>\n",
    "    <p>...</p>...\n",
    "    <div><h2>Section 2 title</h2></div>\n",
    "    <p>...</p>...\n",
    "    \"\"\"\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all h2 tags, which represent section titles\n",
    "    sections = soup.find_all('h2')\n",
    "\n",
    "    # Initialize a list to store the results\n",
    "    section_data = []\n",
    "\n",
    "    # Iterate over each section\n",
    "    for section in sections:\n",
    "        title = section.get_text(strip=True)  # Extract the title text\n",
    "        if section_blacklist is not None:\n",
    "            if title in section_blacklist:\n",
    "                continue\n",
    "        if section_whitelist is not None:\n",
    "            if title not in section_blacklist:\n",
    "                continue\n",
    "        content = []  # Initialize content list for this section\n",
    "        for sibling in section.parent.find_next_siblings():\n",
    "            if len(sibling.select('h2')):  # Stop if the next h2 section starts\n",
    "                break\n",
    "            if sibling.get_text(strip=True):  # Add text content if not empty\n",
    "                content.append(sibling.get_text())\n",
    "\n",
    "        # Join the content list into a single string\n",
    "        content_text = \" \".join(content)\n",
    "\n",
    "        # Append the result as a dictionary\n",
    "        section_data.append({\"title\": title, \"content\": content_text})\n",
    "    return section_data\n",
    "\n",
    "\n",
    "target_folder = Path(\"data/composer_wikipedia_sections/\")\n",
    "\n",
    "section_title_blacklist = [\n",
    "    \"External links\",\n",
    "    \"Further reading\",\n",
    "    \"Sources\",\n",
    "    \"See also\",\n",
    "    \"References\",\n",
    "    \"Contents\",\n",
    "    \"Notes, references and sources\",\n",
    "    \"Notes\",\n",
    "    \"Notes and references\",\n",
    "    \"Recordings\",\n",
    "    \"Compositions\"\n",
    "]\n",
    "def section_composer_wikipedia_page(source_file):\n",
    "    html_content = source_file.read_text()\n",
    "    sections = extract_sections_from_wikipedia_page(\n",
    "        html_content, section_blacklist=section_title_blacklist\n",
    "    )\n",
    "    target_file = target_folder / source_file.with_suffix(\".json\").name\n",
    "    save_to_json(sections, target_file)\n",
    "\n",
    "process_files(\n",
    "    section_composer_wikipedia_page,\n",
    "    source_folder=\"./data/composer_wikipedia_pages/\",\n",
    "    target_folder=target_folder,\n",
    "    replace_existing=False,\n",
    "    num_processes=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277ae46-f643-41d9-804c-5e805840b989",
   "metadata": {},
   "source": [
    "### Summarize the composer wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d24590e9-29d7-4d21-bdda-71cc3db1cb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='126' class='' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [126/126 10:50&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@gpt_function(retries=2)\n",
    "def list_life_events(text: str, exclude_events: list) -> list[dict]:\n",
    "    \"\"\"Return a list of major life events in the given text.\n",
    "    Exclude any event described in the exclude_events list.\n",
    "    Make the summary as informative as possible but only with information\n",
    "    from the text.\n",
    "    Return an empty list if there are no events.\n",
    "    \n",
    "    The output should have this schema:\n",
    "    [{title:str, summary: str, year: int, location: str}...]\n",
    "    \"\"\"\n",
    "\n",
    "target_folder = Path(\"data/composer_event_summaries/\")\n",
    "    \n",
    "def summarize_sections(source_file):\n",
    "    events = []\n",
    "    sections = load_from_json(source_file)\n",
    "    for section in sections:\n",
    "        title = section[\"title\"]\n",
    "        text = source_file.stem + title + \".\\n\" + section[\"content\"]\n",
    "        past_events = [f\"{e['year']} {e['title']}\" for e in events]\n",
    "        section_events = list_life_events(text=text, exclude_events=past_events)\n",
    "        events += [{\"section\": title, **e} for e in section_events]\n",
    "    save_to_json(events, target_folder / source_file.name)\n",
    "\n",
    "process_files(\n",
    "    summarize_sections,\n",
    "    source_folder=\"./data/composer_wikipedia_sections/\",\n",
    "    target_folder=target_folder,\n",
    "    num_processes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbbe19-d1b6-462f-8c27-587fd887ea5c",
   "metadata": {},
   "source": [
    "## Get compositions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49660f8c-987f-46f3-a615-bdddee768789",
   "metadata": {},
   "source": [
    "### Download IMSLP pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "feda7434-f62f-4684-9b98-062428d5002c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='151' class='' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [151/151 00:58&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMSLP_URL = \"https://imslp.org\"\n",
    "\n",
    "def detect_imslp_link(wikipedia_html):\n",
    "    soup = BeautifulSoup(wikipedia_html)\n",
    "    for link in soup.select(\"a\"):\n",
    "        if \"href\" in link.attrs: \n",
    "            href = link.attrs[\"href\"]\n",
    "            if href.startswith(IMSLP_URL + \"/wiki/Category\"):\n",
    "                return href\n",
    "\n",
    "target_folder = Path(\"data/composer_imslp_pages\")\n",
    "\n",
    "def download_imslp_page(wikipedia_html_file):\n",
    "    html = wikipedia_html_file.read_text()\n",
    "    imslp_url = detect_imslp_link(html)\n",
    "    if imslp_url is None:\n",
    "        return\n",
    "    target_file = target_folder / wikipedia_html_file.name\n",
    "    download_page(imslp_url, target_file, sleep_after=1)\n",
    "    \n",
    "process_files(\n",
    "    download_imslp_page,\n",
    "    source_folder=\"./data/composer_wikipedia_pages/\",\n",
    "    target_folder=target_folder,\n",
    "    num_processes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8e425200-b25e-4aa4-8bab-fa1a8acbd56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berg, Alban'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = Path(\"data/composer_imslp_pages/Alban Berg.html\").read_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ba3df1c4-6db2-484f-9300-fd833abdc350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='123' class='' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [123/123 1:44:47&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMSLP_URL = \"https://imslp.org\"\n",
    "\n",
    "def detect_year(txt):\n",
    "    # Regular expression to find all numbers in the text\n",
    "    numbers = re.findall(r'\\b\\d{4}\\b', txt)\n",
    "    for num in numbers:\n",
    "        year = int(num)\n",
    "        if 1000 <= year <= 3000:\n",
    "            return year\n",
    "    return None\n",
    "\n",
    "def get_publication_year(work_url):\n",
    "    work_html = download_page(work_url, sleep_after=1)\n",
    "    try:\n",
    "        soup = BeautifulSoup(work_html)\n",
    "    except:\n",
    "        return None\n",
    "    indicators = [\"First Publication\", \"Composition Year\"]\n",
    "    trs = [\n",
    "        tr for tr in soup.select(\"tr\")\n",
    "        if any([indicator in tr.get_text() for indicator in indicators])\n",
    "    ]\n",
    "    if trs == []:\n",
    "        return None\n",
    "    year = trs[0].select(\"td\")[0].get_text()\n",
    "    return detect_year(year)\n",
    "\n",
    "def get_list_of_work_links(imslp_html):\n",
    "    soup = BeautifulSoup(imslp_html)\n",
    "    title = soup.select(\"h1\")[0].get_text().strip()\n",
    "    imslp_composer = title.replace(\"Category:\", \"\")\n",
    "    return [\n",
    "        a for section in soup.select(\"#mw-pages\")\n",
    "        for a in section.find_all(\"a\", class_=\"categorypagelink\")\n",
    "        if imslp_composer.replace(\" \", \"_\") in a.attrs[\"href\"]\n",
    "    ]\n",
    "\n",
    "def fetch_work_metadata(imslp_work_link):\n",
    "    piece_title = imslp_work_link.text.split(\"(\")[0].strip()\n",
    "    work_url = IMSLP_URL + imslp_work_link.attrs[\"href\"].replace(\" \", \"_\")\n",
    "    year = get_publication_year(work_url)\n",
    "    return {\n",
    "        \"imslp_url\": work_url,\n",
    "        \"year\": year,\n",
    "        \"title\": piece_title\n",
    "    }\n",
    "\n",
    "target_folder = Path(\"data/composer_works\")\n",
    "\n",
    "def get_composition_list(imslp_html_file):\n",
    "    imslp_html = imslp_html_file.read_text()\n",
    "    work_links = get_list_of_work_links(imslp_html)\n",
    "    works_with_metadata = [fetch_work_metadata(link) for link in work_links]\n",
    "    target_file = target_folder / imslp_html_file.with_suffix(\".json\").name\n",
    "    save_to_json(works_with_metadata, target_file)\n",
    "\n",
    "\n",
    "process_files(\n",
    "    get_composition_list,\n",
    "    source_folder=\"./data/composer_imslp_pages/\",\n",
    "    target_folder=target_folder,\n",
    "    num_processes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f06f6-cdde-4d91-aaa1-83f4500089c7",
   "metadata": {},
   "source": [
    "## Download the wikipedia pages for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076f352-7c1c-4f80-af28-0273f77fc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_wikipedia_html_dir = DATA_PATH / \"years_wikipedia_html\" \n",
    "if not year_events_pages.is_dir():\n",
    "    year_events_pages.mkdir()\n",
    "\n",
    "for year in tqdm(range(1500, 2000)):\n",
    "    target_file = years_wikipedia_html_dir / f\"{year}.html\"\n",
    "    if target_file.is_file():\n",
    "        continue\n",
    "    wikipedia_url = f\"https://en.wikipedia.org/wiki/{year}\"\n",
    "    download_page(wikipedia_url, target_file, sleep_after=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddaa791-e1b7-4112-857f-985280d2f8d9",
   "metadata": {},
   "source": [
    "## Get compositions from IMSLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6761a5c5-fb5c-4eb4-9556-825507c026a2",
   "metadata": {},
   "source": [
    "## Compile composer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32482c3-0ef1-4fe1-95c1-0479482f95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "composers_list = load_from_json(DATA_PATH / \"composer_list_with_metadata.json\")\n",
    "wikipedia_urls = load_from_json(DATA_PATH / \"composers_wikipedia_urls.json\")\n",
    "\n",
    "full_composer_data_dir = DATA_PATH / \"full_composer_data\"\n",
    "if not full_composer_data_dir.is_dir():\n",
    "    full_composer_data_dir.mkdir()\n",
    "\n",
    "for composer_metadata_file in load_from_json(\"./data/composer_list.json\"):\n",
    "    full_name = composer[\"full_name\"]\n",
    "    events_json = DATA_PATH / \"deduplicated_events\" / f\"{full_name}.json\"\n",
    "    if not events_json.is_file():\n",
    "        # print (f\"No events for {full_name}\")\n",
    "        continue\n",
    "    compositions_json = DATA_PATH / \"compositions\" / f\"{full_name}.json\"\n",
    "    if not compositions_json.is_file():\n",
    "        # print (f\"No compositions for {full_name}\")\n",
    "        continue\n",
    "    full_composer_data = {**composer}\n",
    "    full_composer_data[\"wikipedia_url\"] = wikipedia_urls[full_name]\n",
    "    full_composer_data[\"events\"] = load_from_json(events_json)\n",
    "    full_composer_data[\"compositions\"] = load_from_json(compositions_json)\n",
    "    save_to_json(full_composer_data, full_composer_data_dir / f\"{full_name}.json\")\n",
    "    # print (composer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e0c1fb-00b0-4a0e-ae82-5c4083266868",
   "metadata": {},
   "outputs": [],
   "source": [
    "composers_list = load_from_json(DATA_PATH / \"composer_list_with_metadata.json\")\n",
    "wikipedia_urls = load_from_json(DATA_PATH / \"composers_wikipedia_urls.json\")\n",
    "\n",
    "full_composer_data_dir = DATA_PATH / \"full_composer_data\"\n",
    "if not full_composer_data_dir.is_dir():\n",
    "    full_composer_data_dir.mkdir()\n",
    "\n",
    "for composer in composers_list:\n",
    "    full_name = composer[\"full_name\"]\n",
    "    events_json = DATA_PATH / \"deduplicated_events\" / f\"{full_name}.json\"\n",
    "    if not events_json.is_file():\n",
    "        # print (f\"No events for {full_name}\")\n",
    "        continue\n",
    "    compositions_json = DATA_PATH / \"compositions\" / f\"{full_name}.json\"\n",
    "    if not compositions_json.is_file():\n",
    "        # print (f\"No compositions for {full_name}\")\n",
    "        continue\n",
    "    full_composer_data = {**composer}\n",
    "    full_composer_data[\"wikipedia_url\"] = wikipedia_urls[full_name]\n",
    "    full_composer_data[\"events\"] = load_from_json(events_json)\n",
    "    full_composer_data[\"compositions\"] = load_from_json(compositions_json)\n",
    "    save_to_json(full_composer_data, full_composer_data_dir / f\"{full_name}.json\")\n",
    "    # print (composer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e6786-677e-43b6-b9c1-27e9843fc281",
   "metadata": {},
   "source": [
    "## Summarize the events of all years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdb707-3372-4378-b936-0058e3f6e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "From the text below, select the top ~10 major events.\n",
    "Prefer major technical advances, or major events which\n",
    "would have made the front page of European newspapers.\n",
    "Prefer events which could have had an impact on citizens\n",
    "and in particular music composers.\n",
    "\n",
    "Return a list of the form [event_1, event_2, ...]\n",
    "where each event has the following schema\n",
    "{\"event\": str, \"summary\": str, \"year\": int, \"city\": str, \"country\": str}\n",
    "The year should always be a single integer, and only an integer.\n",
    "Never use quotation marks inside the summary.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_world_events(text):\n",
    "    prompt = prompt_template + text\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            return ask_chatgpt_with_pythonic_output(prompt, sleep_after=1, model='gpt-4o-mini')\n",
    "        except Exception as err:\n",
    "            if attempt == 2:\n",
    "                raise (err)\n",
    "\n",
    "def extract_events_text(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    events_section = soup.find('h2', string=\"Events\")\n",
    "    \n",
    "    if not events_section:\n",
    "        return None\n",
    "    \n",
    "    # Extract all text between the \"Events\" h2 and the next h2\n",
    "    events_text = []\n",
    "    for sibling in events_section.parent.find_next_siblings():\n",
    "        children = list(sibling.children)\n",
    "        if len(children) and children[0].name == 'h2':\n",
    "            break\n",
    "        events_text.append(sibling.get_text())\n",
    "    \n",
    "    return '\\n'.join(events_text)\n",
    "                \n",
    "years_wikipedia_html_dir = DATA_PATH / \"years_wikipedia_html\" \n",
    "year_world_events_dir = DATA_PATH / \"year_world_events\" \n",
    "if not word_events_dir.is_dir():\n",
    "    word_events_dir.mkdir()\n",
    "\n",
    "for page_path in tqdm(list(years_wikipedia_html_dir.glob(\"*.html\"))):\n",
    "    target_file = year_world_events_dir / (f\"{page_path.name.replace('.html', '')}.json\")\n",
    "    if target_file.is_file():\n",
    "        continue\n",
    "    html = page_path.read_text()\n",
    "    events_text = extract_events_text(html)\n",
    "    selected_events_list = get_world_events(events_text)\n",
    "    save_to_json(selected_events_list, target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9aec3-c533-4220-aa33-bc63c0f26264",
   "metadata": {},
   "source": [
    "### Compile world events to a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82590fbf-8c6e-4643-b33b-0cdc133e96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_world_events = {\n",
    "    year: load_from_json(DATA_PATH / \"year_world_events\" / f\"{year}.json\")\n",
    "    for year in range(1500, 2000)\n",
    "}\n",
    "save_to_json(year_world_events, DATA_PATH / \"year_world_events.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
